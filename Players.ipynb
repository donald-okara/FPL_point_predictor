{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "\n",
    "print(\"Libraries imported successfully......\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. Player data Current Season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to return player url \n",
    "def format_player_url(player_id):\n",
    "    # Define the base URL without curly brackets\n",
    "    base_url = 'https://fantasy.premierleague.com/api/element-summary/{}/'\n",
    "    \n",
    "    # Replace the placeholder '{}' with the actual player_id\n",
    "    formatted_url = base_url.format(player_id)\n",
    "    \n",
    "    return formatted_url\n",
    "\n",
    "# Example usage:\n",
    "player_id = 447  # Replace this with the actual player ID\n",
    "formatted_url = format_player_url(player_id)\n",
    "print(formatted_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported full data from last seasons\n",
    "\n",
    "url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
    "r = requests.get(url)\n",
    "json = r.json()\n",
    "\n",
    "\n",
    "#Convert to df\n",
    "\n",
    "elements_df = pd.DataFrame(json['elements'])\n",
    "elements = elements_df.loc[:,['id','team','web_name','first_name','second_name']]\n",
    "elements = elements.rename(columns = {'id': 'player_id', 'team':'team_id'})\n",
    "# List of columns to drop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_teams = pd.read_csv('filtered_teams.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features_engineered \n",
    ">['Minutes_per_game', 'Player_Strength', 'XA', 'XG', 'XS']\n",
    "\n",
    "intended_features\n",
    ">['fixture_difficulty','kickoff_time', 'started',\n",
    "       'is_home', 'Attack_Strength', 'team_score', 'Form', 'Numerical_Form',\n",
    "       'Win_percentage', 'Strength', 'Defence_Strength', 'Home_Form',\n",
    "       'Home_Numerical_Form', 'Home_Win_percentage', 'Home_Strength',\n",
    "       'Home_Defence_Strength', 'Home_Attack_Strength', 'Away_Form',\n",
    "       'Away_Numerical_Form', 'Away_Win_percentage', 'Away_Strength',\n",
    "       'Away_Defence_Strength', 'Away_Attack_Strength']\n",
    "\n",
    "intended_labels \n",
    ">['goals_scored', 'assists', 'clean_sheets', 'goals_conceded', 'saves']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def load_data_for_player(player_id):\n",
    "    \n",
    "\n",
    "    ######\n",
    "    # Define the URL for the player's data\n",
    "    player_url = format_player_url(player_id)  # You can use the provided function\n",
    "\n",
    "    # Send a GET request to the player's URL\n",
    "    response = requests.get(player_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON data\n",
    "        player_data = response.json()\n",
    "\n",
    "        # Extract the relevant data and preprocess it\n",
    "        #player_fixtures_df = pd.DataFrame(player_data['fixtures'])\n",
    "        player_history_df = pd.DataFrame(player_data['history'])\n",
    "\n",
    "\n",
    "        player_history_df = player_history_df.rename(columns = {'element': 'player_id', 'round': 'event_id'})\n",
    "        columns_to_drop = ['was_home', 'bps', 'kickoff_time','influence', 'creativity',\n",
    "        'threat', 'ict_index', 'starts', 'expected_goals', 'expected_assists',\n",
    "        'expected_goal_involvements', 'expected_goals_conceded', 'value',\n",
    "        'transfers_balance', 'selected', 'transfers_in', 'transfers_out','fixture', 'team_h_score',\n",
    "        'team_a_score']\n",
    "\n",
    "        # Use the drop method to remove the specified columns\n",
    "        player_history_df.drop(columns=columns_to_drop, inplace=True)\n",
    "        player_history_df =  player_history_df.merge(elements, on = 'player_id')\n",
    "        player_history_df = player_history_df.merge(filtered_teams, on = ['team_id','event_id'])\n",
    "        # Perform any necessary data cleaning and feature engineering here\n",
    "        player_history_df['kickoff_time'] = pd.to_datetime(player_history_df['kickoff_time'])\n",
    "\n",
    "        player_history_df.set_index('kickoff_time', inplace=True)\n",
    "\n",
    "        player_history_df = player_history_df[player_history_df['started']==True]\n",
    "        player_history_df['is_home'] = player_history_df['is_home'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "        # Return the processed data for the player\n",
    "        return player_history_df\n",
    "    else:\n",
    "        # Handle the case when the request fails (e.g., return None or raise an exception)\n",
    "        return None\n",
    "\n",
    "\n",
    "# Define a function to process data for a specific player\n",
    "def process_player(player_id):\n",
    "    # Load data for the specified player using player_id\n",
    "    player_data = load_data_for_player(player_id)\n",
    "\n",
    "    if player_data is not None:\n",
    "        player_history_df = player_data\n",
    "\n",
    "        # Define features and labels based on the data for the player\n",
    "        features = ['fixture_difficulty', 'is_home', 'Attack_Strength', 'team_score', 'Numerical_Form', 'Win_percentage', 'Strength', 'Defence_Strength']\n",
    "        labels = ['goals_scored', 'assists', 'clean_sheets', 'goals_conceded', 'saves']\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(player_history_df[features], player_history_df[labels], test_size=0.2, random_state=42)\n",
    "\n",
    "        # Create an empty dictionary to store model results for each label\n",
    "        model_results = {}\n",
    "\n",
    "        from sklearn.feature_selection import SelectKBest, f_regression\n",
    "        feature_selector = SelectKBest(score_func=f_regression, k=len(features))  # Select all features\n",
    "\n",
    "        # Loop through each label\n",
    "        for label_to_predict in labels:\n",
    "            # Define a scikit-learn pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('feature_selector', feature_selector),\n",
    "                ('scaler', StandardScaler(with_mean=False)),  # Set with_mean=False to avoid scaling the label\n",
    "                ('model', tf.keras.Sequential([\n",
    "                    tf.keras.layers.Input(shape=(len(features),)),\n",
    "                    tf.keras.layers.Dense(64, activation='relu'),\n",
    "                    tf.keras.layers.Dense(32, activation='relu'),\n",
    "                    tf.keras.layers.Dense(1)  # Output layer with 1 neuron for regression\n",
    "                ]))\n",
    "            ])\n",
    "            \n",
    "            # Compile the model within the pipeline\n",
    "            pipeline.named_steps['model'].compile(optimizer='adam', loss='mean_squared_error')\n",
    "            \n",
    "            # Train the model within the pipeline\n",
    "            pipeline.named_steps['model'].fit(X_train, y_train[label_to_predict], epochs=100, batch_size=32)\n",
    "            \n",
    "            # Evaluate the model within the pipeline\n",
    "            mse = pipeline.named_steps['model'].evaluate(X_test, y_test[label_to_predict])\n",
    "            model_results[label_to_predict] = mse\n",
    "\n",
    "        # Print the Mean Squared Error for each label\n",
    "        for label, mse in model_results.items():\n",
    "            # Get the 'web_name' for the player ID\n",
    "            player_name = player_data[player_data['player_id'] == player_id]['web_name'].values[0]\n",
    "            \n",
    "            print(f\"Player '{player_name}': Mean Squared Error for '{label}' on the test set: {mse:.2f}\")\n",
    "    else:\n",
    "        # Handle the case when data loading fails\n",
    "        print(f\"Data loading failed for player ID: {player_id}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPL_Team = pd.read_csv('FPL_team.csv')\n",
    "\n",
    "# List of player IDs to process\n",
    "player_ids = FPL_Team.element  # Add the IDs you want to process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through player IDs and process the data\n",
    "for player_id in player_ids:\n",
    "    process_player(player_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iv. Points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
