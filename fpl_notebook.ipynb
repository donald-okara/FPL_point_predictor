{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donald-okara/FPL_point_predictor/blob/main/fpl_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "print(\"Libraries imported successfully......\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.468896Z",
          "iopub.execute_input": "2023-10-18T18:43:34.469467Z",
          "iopub.status.idle": "2023-10-18T18:43:34.476511Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.469416Z",
          "shell.execute_reply": "2023-10-18T18:43:34.475320Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7foHQgxG7sM",
        "outputId": "4b57ca74-e192-4d6b-c2ac-5f664368d5c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully......\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# i. Player data Current Season\n"
      ],
      "metadata": {
        "id": "4v5b9jvRG7so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Function to return player url\n",
        "def format_player_url(player_id):\n",
        "    # Define the base URL without curly brackets\n",
        "    base_url = 'https://fantasy.premierleague.com/api/element-summary/{}/'\n",
        "\n",
        "    # Replace the placeholder '{}' with the actual player_id\n",
        "    formatted_url = base_url.format(player_id)\n",
        "\n",
        "    return formatted_url\n",
        "\n",
        "# Example usage:\n",
        "player_id = 447  # Replace this with the actual player ID\n",
        "formatted_url = format_player_url(player_id)\n",
        "print(formatted_url)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.478925Z",
          "iopub.execute_input": "2023-10-18T18:43:34.479567Z",
          "iopub.status.idle": "2023-10-18T18:43:34.491940Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.479526Z",
          "shell.execute_reply": "2023-10-18T18:43:34.491070Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgu-QLi8G7s0",
        "outputId": "6328212b-c55a-4edf-be1c-47d8b4140a11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://fantasy.premierleague.com/api/element-summary/447/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imported full data from last seasons\n",
        "\n",
        "url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
        "r = requests.get(url)\n",
        "json = r.json()\n",
        "\n",
        "\n",
        "#Convert to df\n",
        "\n",
        "elements_df = pd.DataFrame(json['elements'])\n",
        "elements = elements_df.loc[:,['id','team','web_name','first_name','second_name']]\n",
        "elements = elements.rename(columns = {'id': 'player_id', 'team':'team_id'})\n",
        "# List of columns to drop\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.493095Z",
          "iopub.execute_input": "2023-10-18T18:43:34.493717Z",
          "iopub.status.idle": "2023-10-18T18:43:34.512255Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.493667Z",
          "shell.execute_reply": "2023-10-18T18:43:34.511239Z"
        },
        "trusted": true,
        "id": "xM84zOv6G7s4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_teams = pd.read_csv('/content/drive/MyDrive/FPL/filtered_teams.csv')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.513734Z",
          "iopub.execute_input": "2023-10-18T18:43:34.514268Z",
          "iopub.status.idle": "2023-10-18T18:43:34.525949Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.514239Z",
          "shell.execute_reply": "2023-10-18T18:43:34.525091Z"
        },
        "trusted": true,
        "id": "AovvrCpTG7s7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ii. Feature Engineering"
      ],
      "metadata": {
        "id": "xdJ10ByzG7s_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features_engineered\n",
        ">['Minutes_per_game', 'Player_Strength', 'XA', 'XG', 'XS']\n",
        "\n",
        "intended_features\n",
        ">['fixture_difficulty','kickoff_time', 'started',\n",
        "       'is_home', 'Attack_Strength', 'team_score', 'Form', 'Numerical_Form',\n",
        "       'Win_percentage', 'Strength', 'Defence_Strength', 'Home_Form',\n",
        "       'Home_Numerical_Form', 'Home_Win_percentage', 'Home_Strength',\n",
        "       'Home_Defence_Strength', 'Home_Attack_Strength', 'Away_Form',\n",
        "       'Away_Numerical_Form', 'Away_Win_percentage', 'Away_Strength',\n",
        "       'Away_Defence_Strength', 'Away_Attack_Strength']\n",
        "\n",
        "intended_labels\n",
        ">['goals_scored', 'assists', 'clean_sheets', 'goals_conceded', 'saves']"
      ],
      "metadata": {
        "id": "LjyhxIk6G7tK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# iii. Model Selection"
      ],
      "metadata": {
        "id": "2OnaFBCkG7tN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Don_Team = pd.DataFrame()\n",
        "Don_Team_list = []\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.528622Z",
          "iopub.execute_input": "2023-10-18T18:43:34.529280Z",
          "iopub.status.idle": "2023-10-18T18:43:34.535833Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.529240Z",
          "shell.execute_reply": "2023-10-18T18:43:34.535083Z"
        },
        "trusted": true,
        "id": "Jy3BxTbAG7tQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "num_top_features = 8  # Set it to the total number of features\n",
        "\n",
        "\n",
        "def load_data_for_player(player_id):\n",
        "    # Define the URL for the player's data\n",
        "    player_url = format_player_url(player_id)  # You can use the provided function\n",
        "\n",
        "    # Send a GET request to the player's URL\n",
        "    response = requests.get(player_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON data\n",
        "        player_data = response.json()\n",
        "\n",
        "        # Extract the relevant data and preprocess it\n",
        "        player_history_df = pd.DataFrame(player_data['history'])\n",
        "\n",
        "        player_history_df = player_history_df.rename(columns={'element': 'player_id', 'round': 'event_id'})\n",
        "        columns_to_drop = ['was_home', 'bps', 'kickoff_time', 'influence', 'creativity', 'threat', 'ict_index', 'starts',\n",
        "                           'expected_goals', 'expected_assists', 'expected_goal_involvements', 'expected_goals_conceded',\n",
        "                           'value', 'transfers_balance', 'selected', 'transfers_in', 'transfers_out', 'fixture',\n",
        "                           'team_h_score', 'team_a_score', 'event_id']\n",
        "\n",
        "        # Use the drop method to remove the specified columns\n",
        "        player_history_df.drop(columns=columns_to_drop, inplace=True)\n",
        "        player_history_df = player_history_df.merge(elements, on='player_id')\n",
        "        player_history_df = player_history_df.merge(filtered_teams, on=['team_id'])\n",
        "\n",
        "        # Perform any necessary data cleaning and feature engineering here\n",
        "        player_history_df['kickoff_time'] = pd.to_datetime(player_history_df['kickoff_time'])\n",
        "        player_history_df.set_index('kickoff_time', inplace=True)\n",
        "        player_history_df = player_history_df.fillna(method='ffill')\n",
        "        player_history_df['is_home'] = player_history_df['is_home'].astype(int)\n",
        "        labels = ['goals_scored', 'assists', 'clean_sheets', 'goals_conceded', 'saves']\n",
        "\n",
        "\n",
        "        player_future_fxt = player_history_df[player_history_df['started'] == False].head(3)\n",
        "        player_future_fxt.drop(columns=labels, inplace=True)\n",
        "        player_history_df = player_history_df[player_history_df['started'] == True]\n",
        "\n",
        "        # Return the processed data for the player\n",
        "        return player_history_df, player_future_fxt\n",
        "    else:\n",
        "        # Handle the case when the request fails (e.g., return None or raise an exception)\n",
        "        return None, None\n",
        "\n",
        "num_top_features = 8  # Set it to the total number of features\n",
        "\n",
        "def train_model(X_train, y_train):\n",
        "    # Define a scikit-learn pipeline\n",
        "    pipeline = Pipeline([\n",
        "        ('feature_selector', SelectKBest(score_func=f_regression, k=num_top_features)),\n",
        "        ('scaler', StandardScaler(with_mean=False)),\n",
        "        ('model', tf.keras.Sequential([\n",
        "            tf.keras.layers.Input(shape=(num_top_features,)),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(32, activation='relu'),\n",
        "            tf.keras.layers.Dense(1)  # Output layer with 1 neuron for regression\n",
        "        ]))\n",
        "    ])\n",
        "\n",
        "    # Compile the model within the pipeline with run_eagerly=True\n",
        "    pipeline.named_steps['model'].compile(optimizer='adam', loss='mean_squared_error', run_eagerly=True)\n",
        "\n",
        "    # Train the model within the pipeline on the provided training data\n",
        "    pipeline.named_steps['model'].fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def process_player(player_id):\n",
        "    global Don_Team  # Declare Don_Team as a global variable\n",
        "\n",
        "    # Load data for the specified player using player_id\n",
        "    player_history_df, player_future_fxt = load_data_for_player(player_id)\n",
        "\n",
        "    if player_history_df is not None and player_future_fxt is not None:\n",
        "        # Define features based on the data for the player\n",
        "        features = ['fixture_difficulty', 'is_home', 'Attack_Strength', 'team_score', 'Numerical_Form', 'Win_percentage',\n",
        "                    'Strength', 'Defence_Strength']\n",
        "        labels = ['goals_scored', 'assists', 'clean_sheets', 'goals_conceded', 'saves']\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(player_history_df[features], player_history_df[labels],\n",
        "                                            test_size=0.2, random_state=42)\n",
        "\n",
        "        # Create an empty dictionary to store model results for each label\n",
        "        model_results = {}\n",
        "\n",
        "        for label_to_predict in labels:\n",
        "            # Train a separate model for each label\n",
        "            model = train_model(X_train, y_train[label_to_predict])\n",
        "\n",
        "            # Make predictions for player_future_fxt for the current label\n",
        "            label_features = player_future_fxt[features]\n",
        "            label_predictions = model.named_steps['model'].predict(label_features)\n",
        "\n",
        "            # Create a DataFrame for the player's data\n",
        "            player_data = player_history_df.copy()\n",
        "            player_data['player_fixture_id'] = player_data['player_id'].astype(str) + '_' + player_data['event_id'].astype(str)\n",
        "            player_future_fxt['player_fixture_id'] = player_future_fxt['player_id'].astype(str) + '_' + player_future_fxt['event_id'].astype(str)\n",
        "\n",
        "            # Add predictions to player_future_fxt\n",
        "            player_future_fxt[label_to_predict] = label_predictions\n",
        "\n",
        "            # Join player_data with player_future_fxt\n",
        "            combined_data = player_data.merge(player_future_fxt, on='player_fixture_id')\n",
        "\n",
        "            # Append the combined data to the list\n",
        "            Don_Team_list.append(combined_data)\n",
        "\n",
        "\n",
        "            # Print the predictions for the player's future fixtures\n",
        "            player_name = player_history_df['web_name'].iloc[0]\n",
        "            print(f\"Player '{player_name}': Predictions for future fixtures ({label_to_predict}):\")\n",
        "            print(label_predictions[0][0])\n",
        "\n",
        "            # After processing all players, concatenate the DataFrames in the list into a single DataFrame\n",
        "            Don_Team = pd.concat(Don_Team_list, ignore_index=True)\n",
        "    else:\n",
        "        # Handle the case when data loading fails\n",
        "        print(f\"Data loading failed for player ID: {player_id}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.604549Z",
          "iopub.execute_input": "2023-10-18T18:43:34.604951Z",
          "iopub.status.idle": "2023-10-18T18:43:34.623367Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.604901Z",
          "shell.execute_reply": "2023-10-18T18:43:34.622532Z"
        },
        "trusted": true,
        "id": "uG9MyoLmG7tU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FPL_Team = pd.read_csv('/content/drive/MyDrive/FPL/FPL_team.csv')\n",
        "\n",
        "# List of player IDs to process\n",
        "player_ids = FPL_Team.element  # Add the IDs you want to process\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.625487Z",
          "iopub.execute_input": "2023-10-18T18:43:34.626273Z",
          "iopub.status.idle": "2023-10-18T18:43:34.645195Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.626228Z",
          "shell.execute_reply": "2023-10-18T18:43:34.644351Z"
        },
        "trusted": true,
        "id": "ioAYu8iXG7tc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through player IDs and process the data\n",
        "for player_id in player_ids:\n",
        "    process_player(player_id)\n",
        "    print('Player ID:============>',player_id)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T18:43:34.646419Z",
          "iopub.execute_input": "2023-10-18T18:43:34.647194Z",
          "iopub.status.idle": "2023-10-18T18:43:58.954057Z",
          "shell.execute_reply.started": "2023-10-18T18:43:34.647164Z",
          "shell.execute_reply": "2023-10-18T18:43:58.952384Z"
        },
        "trusted": true,
        "id": "4-9-NYuhG7tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# iv. Points"
      ],
      "metadata": {
        "id": "EPhg9cGUG7tm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZ4wl-B3LpPa"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}